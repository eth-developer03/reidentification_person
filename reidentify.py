# -*- coding: utf-8 -*-
"""REIDENTIFY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sSwdi5VL-on5otZgfKnvBqZvXPlgkpsf

**IMPORTING DEPENDENCIES**
"""

# !pip install opencv-python ultralytics deep_sort_realtime numpy

import cv2
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import os
from pathlib import Path
import matplotlib.pyplot as plt
from IPython.display import Video, display
import time

"""**COMPLETE VIDEO TRACKING**"""

class CompleteVideoTracker:
    def __init__(self, model_path, video_path, output_path=None):
        """
        Initialize tracker with proper video writing safeguards
        """
        self.model_path = model_path
        self.video_path = video_path
        self.output_path = output_path

        # Load model
        print(f"Loading YOLOv11 model from: {model_path}")
        self.model = YOLO(model_path)

        # Initialize tracker
        self.tracker = DeepSort(
            max_age=30, n_init=3, max_cosine_distance=0.3,
            max_iou_distance=0.7, nms_max_overlap=1.0,
            embedder="mobilenet", half=True, bgr=True
        )

        # Video properties
        self.cap = cv2.VideoCapture(video_path)
        if not self.cap.isOpened():
            raise ValueError(f"Cannot open video: {video_path}")

        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"Video properties: {self.width}x{self.height} @ {self.fps}fps, {self.total_frames} frames")

        # Store all processed frames in memory first
        self.all_processed_frames = []
        self.frame_count = 0
        self.total_detections = 0
        self.active_tracks = set()
        self.all_track_ids = set()

        # Colors for visualization
        self.colors = [
            (0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0),
            (0, 128, 255), (128, 255, 0)
        ]

        # Video writing will happen AFTER all frames are processed
        self.video_writer_initialized = False
        self.out = None

    def process_detections(self, results):
        """Process YOLO detection results"""
        detections = []

        if results.boxes is not None:
            for box in results.boxes:
                try:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0].cpu().numpy())
                    class_id = int(box.cls[0].cpu().numpy())

                    if class_id == 0 and confidence > 0.5:
                        x, y, w, h = float(x1), float(y1), float(x2 - x1), float(y2 - y1)
                        detections.append(([x, y, w, h], confidence, 'player'))
                        self.total_detections += 1
                except Exception as e:
                    continue

        return detections

    def draw_tracks(self, frame, tracks):
        """Draw tracking results on frame"""
        current_active = set()

        for track in tracks:
            if not track.is_confirmed():
                continue

            try:
                track_id = int(track.track_id)
                current_active.add(track_id)
                self.all_track_ids.add(track_id)

                # Get bounding box
                ltrb = track.to_ltrb()
                x1, y1, x2, y2 = map(int, ltrb)

                # Choose color
                color = self.colors[track_id % len(self.colors)]

                # Draw bounding box
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)

                # Draw label
                label = "Player " + str(track_id)
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]

                # Background for text
                cv2.rectangle(frame, (x1, y1 - label_size[1] - 15),
                             (x1 + label_size[0] + 10, y1), color, -1)

                # Text
                cv2.putText(frame, label, (x1 + 5, y1 - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)

                # Center point
                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
                cv2.circle(frame, (center_x, center_y), 6, color, -1)

            except Exception as e:
                continue

        self.active_tracks = current_active

        # Draw frame information
        try:
            info_lines = [
                "Frame: " + str(self.frame_count) + "/" + str(self.total_frames),
                "Active Players: " + str(len(current_active)),
                "Total Players: " + str(len(self.all_track_ids))
            ]

            for i, text in enumerate(info_lines):
                y_pos = 40 + i * 35
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]

                # Background
                cv2.rectangle(frame, (15, y_pos - text_size[1] - 10),
                             (15 + text_size[0] + 20, y_pos + 10), (0, 0, 0), -1)

                # Text
                cv2.putText(frame, text, (25, y_pos),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        except:
            pass

    def process_all_frames(self):
        """Process ALL frames first, store in memory"""
        print("Phase 1: Processing all frames and storing in memory...")
        print("(Video file will be created AFTER all frames are processed)")

        try:
            while self.cap.isOpened():
                ret, frame = self.cap.read()
                if not ret:
                    break

                self.frame_count += 1

                try:
                    # Run YOLO detection
                    results = self.model(frame, verbose=False)[0]

                    # Process detections
                    detections = self.process_detections(results)

                    # Update tracker
                    tracks = self.tracker.update_tracks(detections, frame=frame)

                    # Draw tracking results
                    self.draw_tracks(frame, tracks)

                    # Store the processed frame in memory
                    self.all_processed_frames.append(frame.copy())

                    # Progress update
                    if self.frame_count % 10 == 0:
                        progress = (self.frame_count / self.total_frames) * 100
                        active_count = len(self.active_tracks)
                        print("Progress: " + str(round(progress, 1)) + "% - Active players: " + str(active_count))

                except Exception as frame_error:
                    print(f"Error processing frame {self.frame_count}: {frame_error}")
                    # Add a blank frame to maintain timing
                    self.all_processed_frames.append(frame.copy())
                    continue

        except Exception as e:
            print(f"Error during frame processing: {e}")

        finally:
            self.cap.release()

        print(f"\nPhase 1 Complete: Processed {len(self.all_processed_frames)} frames")
        print("All frames are now stored in memory.")

    def write_video_file(self):
        """Write all processed frames to video file"""
        if not self.all_processed_frames:
            print("No frames to write!")
            return False

        if not self.output_path:
            print("No output path specified!")
            return False

        print(f"\nPhase 2: Writing {len(self.all_processed_frames)} frames to video file...")

        try:
            # Try multiple codecs
            codecs_to_try = [
                ('mp4v', cv2.VideoWriter_fourcc(*'mp4v')),
                ('XVID', cv2.VideoWriter_fourcc(*'XVID')),
                ('avc1', cv2.VideoWriter_fourcc(*'avc1')),
                ('H264', cv2.VideoWriter_fourcc(*'H264'))
            ]

            success = False
            for codec_name, fourcc in codecs_to_try:
                print(f"Trying codec: {codec_name}")

                self.out = cv2.VideoWriter(self.output_path, fourcc, self.fps, (self.width, self.height))

                if self.out.isOpened():
                    print(f"✓ Video writer opened with {codec_name}")

                    # Write all frames at once
                    for i, frame in enumerate(self.all_processed_frames):
                        self.out.write(frame)

                        # Progress for writing
                        if (i + 1) % 50 == 0:
                            write_progress = ((i + 1) / len(self.all_processed_frames)) * 100
                            print(f"Writing progress: {write_progress:.1f}%")

                    # Properly close the video writer
                    self.out.release()

                    # Verify the file was created and has reasonable size
                    if os.path.exists(self.output_path):
                        file_size = os.path.getsize(self.output_path)
                        print(f"✓ Video file created: {self.output_path}")
                        print(f"✓ File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")

                        # Quick verification - can we read it back?
                        test_cap = cv2.VideoCapture(self.output_path)
                        if test_cap.isOpened():
                            test_frame_count = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))
                            test_cap.release()
                            print(f"✓ Verification: Video has {test_frame_count} frames")

                            if test_frame_count == len(self.all_processed_frames):
                                print("✓ Frame count matches - video is complete!")
                                success = True
                                break
                            else:
                                print(f"⚠ Frame count mismatch: expected {len(self.all_processed_frames)}, got {test_frame_count}")
                        else:
                            print("⚠ Cannot read back the created video")
                    else:
                        print("✗ Video file was not created")

                else:
                    print(f"✗ Could not open video writer with {codec_name}")
                    if self.out:
                        self.out.release()

            if not success:
                print("✗ All codecs failed. Trying fallback method...")
                return self._fallback_video_creation()

            return True

        except Exception as e:
            print(f"Error writing video: {e}")
            return self._fallback_video_creation()

    def _fallback_video_creation(self):
        """Fallback video creation using imageio"""
        try:
            print("Attempting fallback video creation with imageio...")

            # Install imageio if needed
            try:
                import imageio
            except ImportError:
                print("Installing imageio...")
                os.system("pip install imageio[ffmpeg]")
                import imageio

            # Convert frames from BGR to RGB
            rgb_frames = []
            for i, frame in enumerate(self.all_processed_frames):
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                rgb_frames.append(rgb_frame)

                if (i + 1) % 50 == 0:
                    convert_progress = ((i + 1) / len(self.all_processed_frames)) * 100
                    print(f"Converting frames: {convert_progress:.1f}%")

            # Create video with imageio
            fallback_path = self.output_path.replace('.mp4', '_imageio.mp4')
            print(f"Creating video with imageio: {fallback_path}")

            imageio.mimsave(fallback_path, rgb_frames, fps=self.fps)

            if os.path.exists(fallback_path):
                file_size = os.path.getsize(fallback_path)
                print(f"✓ Fallback video created: {fallback_path}")
                print(f"✓ File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")
                self.output_path = fallback_path  # Update output path
                return True

        except Exception as e:
            print(f"Fallback method also failed: {e}")

        return False

    def process_complete_video(self):
        """Complete processing pipeline"""
        start_time = time.time()

        # Phase 1: Process all frames
        self.process_all_frames()

        processing_time = time.time() - start_time
        print(f"Frame processing took: {processing_time:.1f} seconds")

        # Phase 2: Write video file
        if self.output_path:
            write_start = time.time()
            success = self.write_video_file()
            write_time = time.time() - write_start
            print(f"Video writing took: {write_time:.1f} seconds")

            if not success:
                print("⚠ Video writing failed, but frames were processed successfully")

        # Print final statistics
        self.print_summary()

        return len(self.all_processed_frames) > 0

    def print_summary(self):
        """Print final tracking summary"""
        print("\n" + "="*60)
        print("FINAL TRACKING SUMMARY")
        print("="*60)
        print("Total frames processed: " + str(len(self.all_processed_frames)))
        print("Total detections: " + str(self.total_detections))
        print("Unique players tracked: " + str(len(self.all_track_ids)))
        if len(self.all_processed_frames) > 0:
            avg_detections = round(self.total_detections / len(self.all_processed_frames), 2)
            print("Average detections per frame: " + str(avg_detections))

        if self.output_path and os.path.exists(self.output_path):
            file_size = os.path.getsize(self.output_path)
            print(f"Output video: {self.output_path}")
            print(f"File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")
        print("="*60)

    def display_sample_frames(self, num_frames=5):
        """Display sample frames"""
        if not self.all_processed_frames:
            print("No processed frames available")
            return

        step = max(1, len(self.all_processed_frames) // num_frames)
        sample_frames = self.all_processed_frames[::step][:num_frames]

        fig, axes = plt.subplots(1, len(sample_frames), figsize=(20, 4))
        if len(sample_frames) == 1:
            axes = [axes]

        for i, frame in enumerate(sample_frames):
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            axes[i].imshow(rgb_frame)
            frame_num = i * step
            axes[i].set_title(f'Frame {frame_num}')
            axes[i].axis('off')

        plt.tight_layout()
        plt.show()

def run_complete_tracking():
    """
    Run the complete tracking with proper video creation
    """
    model_path = "/content/best.pt"
    video_path = "/content/15sec_input_720p.mp4"
    output_path = "/content/15sec_complete_tracking.mp4"

    # Check files
    if not os.path.exists(model_path):
        print(f"Model file not found: {model_path}")
        return None

    if not os.path.exists(video_path):
        print(f"Video file not found: {video_path}")
        return None

    print("Starting COMPLETE video processing...")
    print("This will process ALL frames first, then create the video file.")
    print("="*60)

    # Create tracker and process
    tracker = CompleteVideoTracker(model_path, video_path, output_path)
    success = tracker.process_complete_video()

    if success:
        print("\n" + "="*60)
        print("PROCESSING COMPLETE!")
        print("="*60)

        # Display sample frames
        print("Displaying sample frames:")
        tracker.display_sample_frames()

        # Try to display video
        if os.path.exists(output_path):
            print(f"\nTrying to display video: {output_path}")
            try:
                display(Video(output_path, width=800))
                print("✓ Video displayed successfully")
            except Exception as e:
                print(f"Video display failed: {e}")
                print("But the file was created successfully!")

            # Provide download instructions
            print("\n" + "="*50)
            print("TO DOWNLOAD THE COMPLETE VIDEO:")
            print("Run this command in a new cell:")
            print("from google.colab import files")
            print(f"files.download('{output_path}')")
            print("="*50)

        return tracker
    else:
        print("⚠ Processing failed")
        return None

# Run the complete tracking
if __name__ == "__main__":
    tracker = run_complete_tracking()